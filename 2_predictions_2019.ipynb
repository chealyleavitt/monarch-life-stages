{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb6db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4252c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('models/20230212_inception/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4790e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_files = os.listdir('predict_data/')\n",
    "predict_files = [file for file in predict_files if file[-4:]=='.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f36f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_height = 128\n",
    "# img_width = 128\n",
    "# class_names = ['adult', 'egg', 'larva', 'pupa']\n",
    "\n",
    "# predictions = []\n",
    "# scores = []\n",
    "\n",
    "\n",
    "# for file in predict_files[0:1000]:\n",
    "#     img = tf.keras.utils.load_img(\"predict_data/\" + file,\n",
    "#                               target_size=(img_height, img_width)\n",
    "#                              )\n",
    "#     img_array = tf.keras.utils.img_to_array(img)\n",
    "#     img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "#     prediction = model.predict(img_array, verbose = False)\n",
    "#     score = tf.nn.softmax(prediction[0])\n",
    "#     predictions.append(class_names[np.argmax(score)])\n",
    "#     scores.append(100 * np.max(score))\n",
    "\n",
    "# zipped = list(zip(predict_files, predictions, scores))\n",
    "# df = pd.DataFrame(zipped, columns=['filename', 'prediction', 'score'])\n",
    "# df.to_csv('class_predictions_2019_batch1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_height = 128\n",
    "# img_width = 128\n",
    "# class_names = ['adult', 'egg', 'larva', 'pupa']\n",
    "\n",
    "# predictions = []\n",
    "# scores = []\n",
    "\n",
    "\n",
    "# for file in predict_files[10_000:20_000]:\n",
    "#     img = tf.keras.utils.load_img(\"predict_data/\" + file,\n",
    "#                               target_size=(img_height, img_width)\n",
    "#                              )\n",
    "#     img_array = tf.keras.utils.img_to_array(img)\n",
    "#     img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "#     prediction = model.predict(img_array, verbose = False)\n",
    "#     score = tf.nn.softmax(prediction[0])\n",
    "#     predictions.append(class_names[np.argmax(score)])\n",
    "#     scores.append(100 * np.max(score))\n",
    "\n",
    "# zipped = list(zip(predict_files, predictions, scores))\n",
    "# df = pd.DataFrame(zipped, columns=['filename', 'prediction', 'score'])\n",
    "# df.to_csv('class_predictions_2019_batch_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b9fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 128\n",
    "img_width = 128\n",
    "class_names = ['adult', 'egg', 'larva', 'pupa']\n",
    "\n",
    "predictions = []\n",
    "scores = []\n",
    "\n",
    "\n",
    "for file in predict_files[20_000:]:\n",
    "    img = tf.keras.utils.load_img(\"predict_data/\" + file,\n",
    "                              target_size=(img_height, img_width)\n",
    "                             )\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "    prediction = model.predict(img_array, verbose = False)\n",
    "    score = tf.nn.softmax(prediction[0])\n",
    "    predictions.append(class_names[np.argmax(score)])\n",
    "    scores.append(100 * np.max(score))\n",
    "\n",
    "zipped = list(zip(predict_files, predictions, scores))\n",
    "df = pd.DataFrame(zipped, columns=['filename', 'prediction', 'score'])\n",
    "df.to_csv('class_predictions_2019_batch_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45521770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
